---
---

@string{aps = {American Physical Society,}}

@article{ji2023hierarchical,
  abbr={hierarchical},
  title={Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification},
  author={Ke Ji and Yixin Lian and Jingsheng Gao and Baoyuan Wang},
  abstract={We propose the hierarchical verbalizer ("HierVerb"), a multi-verbalizer framework treating HTC as a single- or multi-label classification problem at multiple layers and learning vectors as verbalizers constrained by hierarchical structure and hierarchical contrastive learning.},
  journal={Conference of the Association for Computational Linguistics (ACL)},
  year={2023},
  url={https://arxiv.org/abs/2305.16885},
  html={https://arxiv.org/abs/2305.16885},
  dimensions={true},
  selected={true}
}

@article{gao2023livechat,
  abbr={livechat},
  title={LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming},
  author={Jingsheng Gao and Yixin Lian and Ziyi Zhou and Yuzhuo Fu and Baoyuan Wang},
  abstract={To improve the essential capability of responding and establish a benchmark in the live open-domain scenario, we introduce the LiveChat dataset, composed of 1.33 million real-life Chinese dialogues with almost 3800 average sessions across 351 personas and fine-grained profiles for each persona. LiveChat is automatically constructed by processing numerous live videos on the Internet and naturally falls within the scope of multi-party conversations, where the issues of Who says What to Whom should be considered. },
  journal={Conference of the Association for Computational Linguistics (ACL)},
  year={2023},
  url={https://arxiv.org/abs/2306.08401},
  html={https://arxiv.org/abs/2306.08401},
  dimensions={true},
  selected={true}
}


@article{Guo2021DetectingLA,
  abbr={detectingla},
  title={Detecting Log Anomalies with Multi-Head Attention (LAMA)},
  author={Yicheng Guo and Yujin Wen and Congwei Jiang and Yixin Lian and Yi Wan},
  abstract={We propose LAMA, a multi-head attention based sequential model to process log streams as template activity (event) sequences.},
  journal={Arxiv},
  year={2021},
  url={https://arxiv.org/abs/2101.02392},
  html={https://arxiv.org/abs/2101.02392},
  dimensions={true},
  selected={true}
}


@article{Han2020MultiWOZ2A,
  abbr={multiwoz2a},
  title={MultiWOZ 2.3: A Multi-domain Task-Oriented Dialogue Dataset Enhanced with Annotation Corrections and Co-Reference Annotation},
  author={Ting Han and Ximing Liu and Ryuichi Takanobu and Yixin Lian and Chongxuan Huang and Dazhen Wan and Wei Peng and Minlie Huang},
  abstract={ In this paper, we introduce MultiWOZ 2.3, in which we differentiate incorrect annotations in dialogue acts from dialogue states, identifying a lack of co-reference when publishing the updated dataset.},
  journal={Natural Language Processing and Chinese Computing (NLPCC)},
  year={2020},
  url={https://arxiv.org/abs/2010.05594},
  html={https://arxiv.org/abs/2010.05594},
  dimensions={true},
  selected={true}
}

@article{2022patentDialogSys,
  abbr={dialoguesys},
  title={一种对话模型生成、应用方法、系统、设备及存储介质},
  author={连怡鑫,刘剑锋,杜晓薇,王宝元},
  abstract={本发明公开了一种对话模型生成、应用方法、系统、设备及存储介质，涉及计算机技术领域。一种对话模型生成方法通过获取预设的对话样本；对对话样本进行预处理，得到三元组数据；将三元组数据输入预设的自然语言模型进行语义理解，输出与三元组数据对应的语义意图；将三元组数据和语义意图输入初始神经网络进行训练，得到对话模型。再通过一种对话模型应用方法应用对话模型生成方法生成的对话模型，实现通过多源多模态的数据训练出对话效果较好的对话模型，并基于应用对话模型，**地提高了对话模型的对话迁移场景能力，增强对话回复的信息丰富度和准确率。},
  journal={发明专利:	CN115438170A},
  year={2022},
  url={https://aiqicha.baidu.com/patent/info?referId=a86ef7bea7d15e400bfca2a5c8a42c9207b2afac&pid=31720823858720},
  html={https://aiqicha.baidu.com/patent/info?referId=a86ef7bea7d15e400bfca2a5c8a42c9207b2afac&pid=31720823858720},
  dimensions={true},
  selected={true}
}
